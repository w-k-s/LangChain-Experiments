{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b35517-907c-483a-9902-b7dc781918d1",
   "metadata": {},
   "source": [
    "# 3. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff48ebf-f0aa-4976-95a0-46d0c4ee39f5",
   "metadata": {},
   "source": [
    "Structured Outputs i.e. Mapping the output from an LLM to a python class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca392679-037d-4416-a973-a99e6e33b559",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cca0146d-06ea-442a-92cb-5d469339a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "assert os.environ[\"LANGSMITH_TRACING\"] is not None\n",
    "assert os.environ[\"LANGSMITH_API_KEY\"] is not None\n",
    "assert os.environ[\"LANGSMITH_PROJECT\"] is not None\n",
    "assert os.environ[\"OPENAI_API_KEY\"] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13b139db-ee39-4ba8-8136-ba2a7f440deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a23cf2-b255-4267-a180-cc4159909133",
   "metadata": {},
   "source": [
    "## 3.1 Tool-Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1547e-2eb2-4b37-8a48-9f16e7a6eeb8",
   "metadata": {},
   "source": [
    "- Tool calling in LangChain enables an LLM to interact with external systems, such as making API calls, querying databases, or executing code.\n",
    "- When invoking a tool, the LLM must generate inputs that conform to the tool’s expected input schema—for example, a structured JSON payload or SQL query format.\n",
    "- Tool responses also follow a defined schema, allowing the LLM or orchestrator to interpret the results reliably.\n",
    "- **Important**: Not all models support tool calling but the popular ones (Gemini, ChatGPT and Claude do)\n",
    "\n",
    "![](./docs/llms_use_tools_to_interact_with_systems.png)\n",
    "The LLM uses natural language to interact with humans and tools to ineract with systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f24091-e52e-47bf-bcf2-19851034d7fd",
   "metadata": {},
   "source": [
    "## 3.2 Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc879ac8-c495-45ee-8fa9-fbff689dbf01",
   "metadata": {},
   "source": [
    "- In this tutorial, we will use tool-calling features of chat models to extract structured information from unstructured text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a98290e-f9b9-4fcb-84f0-1017f621ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Alan Smith', hair_color='blond', height_in_meters='1.83')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Define a custom prompt to provide instructions and any additional context.\n",
    "# 1) You can add examples into the prompt template to improve extraction quality\n",
    "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
    "#    about the document from which the text was extracted.)\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=Person)\n",
    "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e768d-24e2-4ada-83f6-72c84fe43cbe",
   "metadata": {},
   "source": [
    "**IMPORTANT PRACTICES**:\n",
    "1. Document the attributes **AND** the schema itself: This information is sent to the LLM and is used to improve the quality of information extraction.\n",
    "2. Do not force the LLM to make up information! Above we used Optional for the attributes allowing the LLM to output None if it doesn't know the answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2a322-2507-47fd-8697-a6b87aa9a0bd",
   "metadata": {},
   "source": [
    "### 3.2.1 Multiple Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d4c9ae-7075-4b3a-9cc2-c394500e5f7a",
   "metadata": {},
   "source": [
    "- In most cases, you should be extracting a list of entities rather than a single entity.\n",
    "- This can be easily achieved using pydantic by nesting models inside one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d08d96d6-e1cb-40f7-91e5-b7a0ca9f029d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None)])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=Data)\n",
    "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e88c34f-e766-4ba1-8145-049f108741ca",
   "metadata": {},
   "source": [
    "## 3.3 Tagging\n",
    "\n",
    "Tagging means labeling a document with classes such as:\n",
    "\n",
    "- Sentiment\n",
    "- Language\n",
    "- Style (formal, informal etc.)\n",
    "- Covered topics\n",
    "- Political tendency\n",
    "\n",
    "Tagging has a few components:\n",
    "\n",
    "- `function`: Like extraction, tagging uses functions to specify how the model should tag a document\n",
    "- `schema`: defines how we want to tag the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7157d241-2639-4808-b37b-9ae55e74ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
    "    aggressiveness: int = Field(\n",
    "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
    "    )\n",
    "    language: str = Field(description=\"The language the text is written in\")\n",
    "\n",
    "\n",
    "# Structured LLM\n",
    "structured_llm = model.with_structured_output(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef446348-657e-41cf-9f7b-376abe045599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = structured_llm.invoke(prompt)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd7762-b17e-4868-a3e4-aa21ba49c0ca",
   "metadata": {},
   "source": [
    "### 3.3.1 Finer Control over the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08955a29-a442-4ce3-93d3-30e748bd1d03",
   "metadata": {},
   "source": [
    "Careful schema definition gives us more control over the model's output.\n",
    "\n",
    "Specifically, we can define:\n",
    "- Possible values for each property\n",
    "- Description to make sure that the model understands the property\n",
    "- Required properties to be returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c5e48d3-f765-4397-a4c2-2a60ee39eb16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'happy', 'aggressiveness': 1, 'language': 'spanish'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classification(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )\n",
    "\n",
    "tagging_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'Classification' function.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
    "    Classification\n",
    ")\n",
    "\n",
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cde25b63-6f9b-49d7-9a06-0ce2929ec999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentiment': 'sad', 'aggressiveness': 1, 'language': 'spanish'},\n",
       " {'sentiment': 'neutral', 'aggressiveness': 1, 'language': 'spanish'},\n",
       " {'sentiment': 'sad', 'aggressiveness': 5, 'language': 'french'},\n",
       " {'sentiment': 'sad', 'aggressiveness': 3, 'language': 'german'},\n",
       " {'sentiment': 'happy', 'aggressiveness': 1, 'language': 'english'},\n",
       " {'sentiment': 'sad', 'aggressiveness': 5, 'language': 'english'},\n",
       " {'sentiment': 'neutral', 'aggressiveness': 3, 'language': 'english'},\n",
       " {'sentiment': 'neutral', 'aggressiveness': 1, 'language': 'english'},\n",
       " {'sentiment': 'neutral', 'aggressiveness': 1, 'language': 'english'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for inp in [\n",
    "        \"muy amigo esta muerto\",\n",
    "        \"donde esta la bibliotecha\",\n",
    "        \"merde!\",\n",
    "        \"ich habe kein mehr Gelt. Oh well, i can always rob a bank\",\"Will you marry me?\",\n",
    "        \"I'd marry you over my dead body you ugly 4-eyed piece of human excrement\",\n",
    "        \"All the other kids with the pumped up kicks better run, better run, outrun my gun\",\n",
    "        \"Jojo mogo roko wowo mukaka bamo\",\n",
    "    \"23423 324342 2342290 00\"\n",
    "]:\n",
    "    prompt = tagging_prompt.invoke({\"input\": inp})\n",
    "    response = llm.invoke(prompt)\n",
    "    results.append(response.model_dump())\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d37c7-f4ad-4033-a04e-bca94beb9eeb",
   "metadata": {},
   "source": [
    "## 3.5 Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6ad5ec2-1d40-4081-8cea-aa99dfbf5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class BudgetEntry(BaseModel):\n",
    "    amount: Optional[float] = Field(description = \"The income or expense amount\",default=0.0)\n",
    "    currency: Optional[str] = Field(description = \"The currency of the amount\",default='AED')\n",
    "    creditOrDebit: Optional[str] = Field(description = \"Credit or Debit. Debit if the amount was debited/spent. credit if the amount was received. Defaults to credit\", enum=[\"C\",\"D\"],default='D')\n",
    "    memo: Optional[str] = Field(description=\"Short description of the credit/debit event e.g. Shopping\")\n",
    "    category: str = Field(description=\"The category of the credit/debit event e.g. Bills\", enum=[\"Salary\",\"Bills\",\"Rent\",\"Shopping\",\"Car\",\"Home\"])\n",
    "\n",
    "structured_llm = model.with_structured_output(BudgetEntry)\n",
    "system_template = \"\"\"\n",
    "Extract the properties of the 'BudgetEntry' function from the following input. \n",
    "\"\"\"\n",
    "user_input = \"20 aed on a haircut\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{user_input}\")])\n",
    "prompt = prompt_template.invoke({\"user_input\": user_input})\n",
    "response = structured_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "106623ee-3f82-4401-8bef-b471bb159027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 20.0,\n",
       " 'currency': 'AED',\n",
       " 'creditOrDebit': 'D',\n",
       " 'memo': 'Haircut',\n",
       " 'category': 'Shopping'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ba716-de4f-41a6-8c8e-20edcfccbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BudgetEntries(BaseModel):\n",
    "    entries: list[BudgetEntry]\n",
    "\n",
    "structured_llm = model.with_structured_output(BudgetEntries)\n",
    "user_input = \"20 aed on a haircut\"\n",
    "prompt = prompt_template.invoke({\"user_input\": user_input})\n",
    "response = structured_llm.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
