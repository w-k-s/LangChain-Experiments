{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b35517-907c-483a-9902-b7dc781918d1",
   "metadata": {},
   "source": [
    "# 4. Few Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca392679-037d-4416-a973-a99e6e33b559",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca0146d-06ea-442a-92cb-5d469339a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # load environment variables from .env file (requires `python-dotenv`)\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "assert os.environ[\"LANGSMITH_TRACING\"] is not None\n",
    "assert os.environ[\"LANGSMITH_API_KEY\"] is not None\n",
    "assert os.environ[\"LANGSMITH_PROJECT\"] is not None\n",
    "assert os.environ[\"OPENAI_API_KEY\"] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b139db-ee39-4ba8-8136-ba2a7f440deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a23cf2-b255-4267-a180-cc4159909133",
   "metadata": {},
   "source": [
    "## 3.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1547e-2eb2-4b37-8a48-9f16e7a6eeb8",
   "metadata": {},
   "source": [
    "- Few-shot prompting is a technique used with large language models (LLMs) where you provide a small number of examples (typically 1‚Äì5) within the prompt to show the model how to perform a task\n",
    "- Importantly, the examples should include \"negatives\" so that the LLM understands how to handle such cases.\n",
    "- Few Shot Prompting typically involvces alternating user and assistant messages that demonstrate the desired behaviour before providing the actual prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd20349d-3d8e-4302-b706-adcca18240a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 ü¶ú 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"2 ü¶ú 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 ü¶ú 4\"},\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f990789-6141-44d4-a953-357dbc67090c",
   "metadata": {},
   "source": [
    "## 3.2 Few Shot Prompting with Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06677779-5bc2-4aa6-aa27-396620edb8a4",
   "metadata": {},
   "source": [
    "- We can use Few Shot Prompting to \"teach\" an LLM to call a tool correctly. For example: we can \"Teach\" an LLM to fill a schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9ceb88-8e85-4e8d-8d37-67c3646071a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "\n",
    "    # ^ Doc-string for the entity Person.\n",
    "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
    "    # and it can help to improve extraction results.\n",
    "\n",
    "    # Note that:\n",
    "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
    "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
    "    # Having a good description can help improve extraction results.\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Data(BaseModel):\n",
    "    \"\"\"Extracted data about people.\"\"\"\n",
    "\n",
    "    # Creates a model so that we can extract multiple entities.\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c198be-09b0-40f3-b665-c2fa1169d945",
   "metadata": {},
   "source": [
    "**For Few-Shot Prompting, Different LLM providers expect different message sequences**. Typically this starts with:\n",
    "\n",
    "1. User message\n",
    "2. AI message with tool call\n",
    "3. Tool message with result\n",
    "4. (Optional) A final AI message containing some sort of response.\n",
    "\n",
    "- LangChain includes a utility function `tool_example_to_messages` that will generate a valid sequence for LLM providers.\n",
    "- Developers wioll just need to provide the user message and the pydantic output as shown in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255ea94e-6188-498c-a61d-4c02dac47dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (508f6ca7-2d0d-4fec-be0a-fb118d2d0a10)\n",
      " Call ID: 508f6ca7-2d0d-4fec-be0a-fb118d2d0a10\n",
      "  Args:\n",
      "    people: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected no people.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Fiona traveled far from France to Spain.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Data (e8628411-b9b9-4e86-9906-2c482a2a81c2)\n",
      " Call ID: e8628411-b9b9-4e86-9906-2c482a2a81c2\n",
      "  Args:\n",
      "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected people.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/zrl57ryx10l614s07glvwcnh0000gp/T/ipykernel_85844/3367841236.py:23: LangChainBetaWarning: The function `tool_example_to_messages` is in beta. It is actively being worked on, so the API may change.\n",
      "  messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
    "        Data(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"Fiona traveled far from France to Spain.\",\n",
    "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call in examples:\n",
    "    if tool_call.people:\n",
    "        # This final message is optional for some providers\n",
    "        ai_response = \"Detected people.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no people.\"\n",
    "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1249c25d-4a3f-4421-aef9-e21a1a1ada3a",
   "metadata": {},
   "source": [
    "Notice how we only provided the user message and the expected Pydantic output, and `tool_example_to_messages` converted this to the correct sequence of Human, Ai, Tool, Ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddb5bb-49eb-4779-afc7-48c3198d8cad",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Human     ‚îÇ \"The ocean is vast and blue...\"\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   AI       ‚îÇ Calls tool `Data` with args:\n",
    "‚îÇ            ‚îÇ   people: []\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Tool     ‚îÇ Confirms tool call executed\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   AI       ‚îÇ \"Detected no people.\"\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ce87f-fb23-4123-a805-1e07cf968e01",
   "metadata": {},
   "source": [
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Human     ‚îÇ \"Fiona traveled far from France to Spain.\"\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   AI       ‚îÇ Calls tool `Data` with args:\n",
    "‚îÇ            ‚îÇ   people: [{ name: \"Fiona\", height: None, hair: None }]\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Tool     ‚îÇ Confirms tool call executed\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   AI       ‚îÇ \"Detected people.\"\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d259c6-eceb-4638-a97f-d6d010876bb6",
   "metadata": {},
   "source": [
    "When invoking the LLM, these training examples are placed before the actual question. The model uses them as guidance and then produces its final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956fea77-db6c-4e07-847c-6790dd1b9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
    "}\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c07f3cd5-bc71-4d2a-84c1-f58d6f8507de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke([message_no_extraction])  # without few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087f9804-1b32-49c8-8861-5c9f2c405770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(people=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.invoke(messages+[message_no_extraction]) # with few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d37c7-f4ad-4033-a04e-bca94beb9eeb",
   "metadata": {},
   "source": [
    "## 3.5 Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ad5ec2-1d40-4081-8cea-aa99dfbf5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "class BudgetEntry(BaseModel):\n",
    "    amount: Optional[float] = Field(description = \"The income or expense amount\",default=0.0)\n",
    "    currency: Optional[str] = Field(description = \"The currency of the amount\",default='AED')\n",
    "    creditOrDebit: Optional[str] = Field(description = \"Credit or Debit. Debit if the amount was debited/spent. credit if the amount was received. Defaults to credit\", enum=[\"C\",\"D\"],default='D')\n",
    "    memo: Optional[str] = Field(description=\"Short description of the credit/debit event e.g. Shopping\")\n",
    "    category: str = Field(description=\"The category of the credit/debit event e.g. Bills\", enum=[\"Salary\",\"Bills\",\"Rent\",\"Shopping\",\"Car\",\"Home\"])\n",
    "\n",
    "class Extract(BaseModel):\n",
    "    entry:  Optional[BudgetEntry] = Field(description = \"The budget entry if all of required the details of the transaction were present in the text\"),\n",
    "    success: bool = Field(description=\"True/False value indicating if the text contained all required details for a transaction\")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"Fifty dollars for a t-shirt\",\n",
    "        Extract(success=True, entry=BudgetEntry(amount=50., currency=\"USD\",creditOrDebit=\"D\",memo=\"T-Shirt\",category=\"Shopping\")),\n",
    "    ),\n",
    "    (\n",
    "        \"And having the same one as six other people in this club is a hella don't\",\n",
    "        Extract(success=False, entry=None),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "messages = []\n",
    "\n",
    "for txt, tool_call in examples:\n",
    "    if tool_call.success:\n",
    "        # This final message is optional for some providers\n",
    "        ai_response = \"Detected entry.\"\n",
    "    else:\n",
    "        ai_response = \"Detected no entry.\"\n",
    "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106623ee-3f82-4401-8bef-b471bb159027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Fifty dollars for a t-shirt\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Extract (1e2eed8c-ad7e-4107-af4e-3e334e406f7d)\n",
      " Call ID: 1e2eed8c-ad7e-4107-af4e-3e334e406f7d\n",
      "  Args:\n",
      "    entry: {'amount': 50.0, 'currency': 'USD', 'creditOrDebit': 'D', 'memo': 'T-Shirt', 'category': 'Shopping'}\n",
      "    success: True\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected entry.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "And having the same one as six other people in this club is a hella don't\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Extract (60ab783b-c427-42c6-9777-3411cc16db1f)\n",
      " Call ID: 60ab783b-c427-42c6-9777-3411cc16db1f\n",
      "  Args:\n",
      "    entry: None\n",
      "    success: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "You have correctly called this tool.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Detected no entry.\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb8cccf6-87ad-4cd6-b967-f5e00a8cb170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/W.Sheikh/Developer/Langchain/.venv/lib/python3.13/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The budget entry if all of required the details of the transaction were present in the text'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/Users/W.Sheikh/Developer/Langchain/.venv/lib/python3.13/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The budget entry if all of required the details of the transaction were present in the text'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Extract(entry=BudgetEntry(amount=3999.0, currency='USD', creditOrDebit='D', memo='Apple Vision Pro', category='Shopping'), success=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_with_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Apple Vision Pro thingy for $3999\",\n",
    "}\n",
    "\n",
    "# Add your few-shot examples + a new query\n",
    "response = model.invoke(messages + [message_with_extraction])\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=Extract)\n",
    "structured_llm.invoke(messages + [message_with_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5421dce7-03d2-4f7c-8246-d3f38aaeda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/W.Sheikh/Developer/Langchain/.venv/lib/python3.13/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The budget entry if all of required the details of the transaction were present in the text'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
      "/Users/W.Sheikh/Developer/Langchain/.venv/lib/python3.13/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The budget entry if all of required the details of the transaction were present in the text'),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Extract(entry=BudgetEntry(amount=0.99, currency='USD', creditOrDebit='D', memo='Unknown purchase', category='Shopping'), success=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_with_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"But shit, it was ninety-nine cents\",\n",
    "}\n",
    "\n",
    "# Add your few-shot examples + a new query\n",
    "response = model.invoke(messages + [message_with_extraction])\n",
    "\n",
    "structured_llm = model.with_structured_output(schema=Extract)\n",
    "structured_llm.invoke(messages + [message_with_extraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3cc1b-5501-49e9-9000-b085980c8b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
