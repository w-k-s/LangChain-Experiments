{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd88394-3b53-4ae8-9c5c-00573b01bfdd",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0f761-8f80-4ebf-b9a3-70431f3ac856",
   "metadata": {},
   "source": [
    "## Documents\n",
    "\n",
    "- A Document is the unix of text that the LLM processes in order to answer queries. \n",
    "- A Document is not necessarly the whole file: files are typically chunked. Documents usually contain metadata including the name of the original document, the page from where the part of the document was extracted, author e.t.c.\n",
    "- Full texts are usually split into document chunks to optimise LLm output. Larger chunks = more stuff in context = more risk of hallunication. \n",
    "\n",
    "## Embeddings\n",
    "\n",
    "- LLMs store text as vectors in a high-dimensional space\n",
    "- In this space, the position of each point (embedding) reflects the meaning of its corresponding text.\n",
    "Just as similar words might be close to each other in a thesaurus, similar concepts end up close to each other in this embedding space.\n",
    "- In simpler words: LLMs store text in \"space\". The way that text is store relative to each other captures the relationship between the text. So text close to each other might have similar meaning. Text at a higher vertical axis might describe parent chld relationship. \n",
    " \n",
    "## Vector Stores\n",
    "\n",
    "- A vector store is a specialised database for storing and querying embeddings. It supports standard operations like create, read, update, and delete (CRUD).\n",
    "- For retrieval, it allows searching for semantically similar text by comparing embedding vectors using similarity metrics such as cosine similarity.\n",
    "\n",
    "\n",
    "## Tool Calling\n",
    "- Tool calling enables an LLM to interact with systems e.g. calling an API or querying a database.\n",
    "- When interacting with external tools, the request and response typically needs to confirm to a schema e.g. API Request Payload, SQL query structure.\n",
    "\n",
    "## Structured Output\n",
    "\n",
    "- \n",
    "\n",
    "## Few-shot Prompting\n",
    "- Few-shot prompting is a technique used with large language models (LLMs) where you provide a small number of examples (typically 1â€“5) within the prompt to show the model how to perform a task\n",
    "- Importantly, the examples should include \"negatives\" so that the LLM understands how to handle such cases.\n",
    "- **Different chat model providers impose different requirements for valid message sequences**\n",
    "\n",
    "## Chatbots\n",
    "- By default, an LLM does not retain the context from previous invocations. For example, if you tell an LLM your name in one invocation, it will not \"remember\" your name in the subsequent invocations\n",
    "- For the LLM to remember the name, the chat history has to be sent with each invocation\n",
    "- Tools like LangGraph enable this.\n",
    "\n",
    "## LangGraph\n",
    "- **LangGraph** is an open-source library from the creators of LangChain that is used to build A stateful, multi-step agent/workflow applications with reliable execution and persistence.\n",
    "- Importantly, Human/Agent interactions are modeled as nodes in a graph which makes the orchestration between humans and agents visible and easy to debug.\n",
    "\n",
    "#### Nodes\n",
    "- A node is a single action: e.g., call an LLM, run a tool, query a database, or invoke custom code.\n",
    "- Nodes can represent different actors (LLMs, tools, humans).\n",
    "- In case of a human, the graph encodes when to pause for human input, how to resume, and how actors exchange state.\n",
    "\n",
    "#### Edges\n",
    "- Edges connect nodes and decide what runs next.\n",
    "- They can be unconditional, conditional (branching), looping, or fan-out/fan-in (parallel paths and joins).\n",
    "- Graph branches can run in parallel\n",
    "\n",
    "#### Graph\n",
    "- A workflow is the directed graph of nodes and edges.\n",
    "- This makes the system explicit and debuggable: you can see the exact path the execution took.\n",
    "\n",
    "#### State\n",
    "- The workflow carries a state object (typically a structured dict/schema) that persists across nodes.\n",
    "- Nodes read from state and propose updates to state rather than mutating it in place\n",
    "- After each node runs, LangGraph materialises a new state version.\n",
    "- This **immutability per step** yields reproducibility, diff-ability, and clear audit trails.\n",
    "\n",
    "#### Checkpoints\n",
    "- Each step can be checkpointed (state snapshot + metadata).\n",
    "- Checkpoints and state can be stored in memory or external stores (DBs, object storage).\n",
    "\n",
    "- With checkpoints, you can retry or reroute without losing prior work.\n",
    "- This enables resume after failure/timeouts, deterministic replay, and precise debugging from any point.\n",
    "\n",
    "#### Thread\n",
    "- A thread is one concrete run of the graph (e.g., a single user session).\n",
    "- Each thread has its own state history and checkpoints, isolating concurrent users/sessions cleanly.\n",
    "\n",
    "![](./docs/langgraph-checkpoints.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25317641-4fc9-4af1-9ee9-5ed5ba9c5a28",
   "metadata": {},
   "source": [
    "```python\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"), # state['messages'] will be inserted in this placeholder.\n",
    "    ]\n",
    ")\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages] # state stores messages\n",
    "    language: str # messages contain a variable 'language' whose value also needs to be stored with the mesages\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
